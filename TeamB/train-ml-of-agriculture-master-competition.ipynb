{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import torch \nimport numpy as np\nimport sklearn\nfrom sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\nfrom sklearn import  ensemble, preprocessing, metrics\nimport matplotlib\nimport seaborn\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom torch.utils.data import Dataset,DataLoader\nfrom xgboost import XGBClassifier\nfrom torch import nn\nimport os\nBASEPATH=\"../input/agriculture-master-competition\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_torch(seed=2021):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nseed_torch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_csvfile(filepath):\n    df = pd.read_csv(filepath)\n    return df\ninput_df = read_csvfile(os.path.join(BASEPATH,\"train_data.csv\"))\nlabelcolumns = list(input_df.columns[20:])\nfeaturecolumns = list(input_df.columns[1:20])\nfeaturecolumns.remove(\"d.rainfall_detect\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def removeOutlier(input_df):\n    input_df = input_df[input_df[\"d.wind_speed\"] != -9999]\n    input_df = input_df[input_df[\"d.photometric\"]<input_df[\"d.photometric\"].std()*3]\n    input_df = input_df[input_df[\"d.outside_photometric\"]<input_df[\"d.outside_photometric\"].std()*3]\n    input_df = input_df[input_df[\"d.radiometric\"]<input_df[\"d.radiometric\"].std()*3]\n    return input_df\ninput_df = removeOutlier(input_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def changeTimeFormat(input_df):\n    #print(input_df[\"d.log_time\"].iloc[6500])\n    input_df[\"d.log_time\"] = [int(i.split(' ')[0].split('/')[1].zfill(2)+i.split(' ')[0].split('/')[2].zfill(2) + i.split(' ')[1].replace(':',''))/1e5 for i in input_df[\"d.log_time\"].tolist()]\n    #print(input_df[\"d.log_time\"].iloc[6500])\n    return input_df\ninput_df=changeTimeFormat(input_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def logData(df,columnsname):\n    df[columnsname]=df[columnsname].apply(lambda x: x if x!=0 else 000.1)\n    df[columnsname] = np.log(df[columnsname]).fillna(0)\n    return df\ninput_df = logData(input_df,\"d.wind_direction\")\ninput_df[featurecolumns].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(input_df[\"d.wind_direction\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier(n_estimators=100)\ndef replacezerovalues(df,columnsname,train=True):\n    featureX = df[df[columnsname] != 0][featurecolumns].copy()\n    LabelX =featureX[columnsname].copy()\n    featureX = featureX.drop(columns=columnsname)\n    \n    #rf = RandomForestRegressor(n_estimators = 50, random_state = 2021)\n    #rf.fit(featureX,LabelX)\n    if train:\n        #xgb = XGBClassifier(n_estimators=100)\n        xgb.fit(np.array(featureX), np.array(LabelX))\n    \n    featureY = df[featurecolumns].copy()\n    featureY = featureY.drop(columns=columnsname)\n    \n    newLabelY = xgb.predict(np.array(featureY))\n    df[columnsname] = newLabelY\n    return df\ncolumnsnames=[\"d.wind_speed\"]#,\"d.radiometric\"]#,\"d.outside_photometric\",\"d.photometric\"]\n#columnsnames=[\"d.wind_speed\"]\nfig ,ax = plt.subplots(len(columnsnames)+1,2,figsize=(20,20))\nfor idx,columnsname in enumerate(columnsnames):\n    sns.distplot(input_df[columnsname],ax=ax[idx,0])\n    input_df = replacezerovalues(input_df,columnsname)\n    #input_df = logData(input_df,columnsname)\n    sns.distplot(input_df[columnsname],ax=ax[idx,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def showDataHist():\n    fig,axis = plt.subplots(6,3,figsize = (20,40))\n    for idx,cln in enumerate(featurecolumns):\n        sns.distplot(input_df[cln],ax=axis[idx//3,idx%3])\n    fig.show()\nshowDataHist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dataNormalized(feature_df,zeromean=True):\n    if zeromean:\n        feature_df = (feature_df - feature_df.mean())/feature_df.std()\n    else:\n        feature_df=(feature_df-feature_df.min())/(feature_df.max()-feature_df.min())\n    return feature_df\nnormalized_feature = dataNormalized(input_df[featurecolumns],True)\ninput_df[featurecolumns] = normalized_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def balanceDataset(train_df,valid_df,minnum):\n    #for lc in labelcolumns:\n    #    print(len(train_df[train_df[lc] == 0]),len(valid_df[valid_df[lc] == 0]),len(train_df[train_df[lc] == 1]),len(valid_df[valid_df[lc] == 1]))\n    #print(\"===\")\n    for lc in labelcolumns:\n        l=0 if len(valid_df[valid_df[lc] == 1]) > len(valid_df[valid_df[lc] == 0]) else 1\n        trainn = len(train_df[train_df[lc] == l])\n        validn=len(valid_df[valid_df[lc] == l])\n        if validn+1 < minnum*(trainn+validn):\n            moven = (trainn+validn)*minnum-validn\n            move_rows = train_df[train_df[lc] == l].sample(frac=moven/trainn).copy()\n            valid_df=valid_df.append(move_rows)\n            train_df=train_df.drop(move_rows[\"index\"])\n\n            validnn=len(valid_df[valid_df[lc] == (not l)])\n            if validnn > len(move_rows):\n                move_rows = valid_df[valid_df[lc] == (not l)].sample(frac=len(move_rows)/validnn).copy()\n                train_df=train_df.append(move_rows)\n                valid_df=valid_df.drop(move_rows[\"index\"])\n    #for lc in labelcolumns:\n    #    print(len(train_df[train_df[lc] == 0]),len(valid_df[valid_df[lc] == 0]),len(train_df[train_df[lc] == 1]),len(valid_df[valid_df[lc] == 1]))\n    return train_df,valid_df\n\n\ndef splitDataframe(df,train_sample):\n    shuffle_df = df.sample(frac=1,random_state=2021)\n    train_df,valid_df = np.split(shuffle_df,[int(train_sample*len(shuffle_df))])\n    #print(len(train_df),len(valid_df))\n    train_df,valid_df=balanceDataset(train_df,valid_df,0.01)\n    #print(len(train_df),len(valid_df))\n    return train_df,valid_df\n            \ntrain_df,valid_df=splitDataframe(input_df,0.98)\nprint(len(train_df),len(valid_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def trainDataframeBalance(df):\n    balancecolumns = labelcolumns[:6]\n    balance_df = pd.DataFrame(columns = df.columns)\n    for cn in balancecolumns:\n        balance_df=balance_df.append(df[df[cn] == 0].copy())\n        \n    balancecolumns = labelcolumns[-2:]\n    for cn in balancecolumns:\n        balance_df=balance_df.append(df[df[cn] == 1].copy())\n        \n    #showactuatorplot(balance_df)\n    balancecolumns = labelcolumns[:6]\n    for cn in balancecolumns:\n        tmp_zero=balance_df[balance_df[cn] == 0]\n        tmp_one=balance_df[balance_df[cn] == 1]\n        if 2*len(tmp_one)<len(tmp_zero):\n            balance_df=balance_df.append(df[df[cn] == 1].sample(frac=(len(tmp_zero)-len(tmp_one))/(len(tmp_zero)*3)))\n    #showactuatorplot(balance_df)\n    return balance_df\n#balance_df=trainDataframeBalance(train_df)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CFG():\n    def __init__(self):\n        self.BATCHSIZE=100\n        self.EPOCH=200\n        self.savescore=80\n        self.DEVICE=torch.device('cuda')\ncfg=CFG()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def splitRandomforestDataset(df):\n    featureX = [r.tolist() for i,r in df[featurecolumns].iterrows()]\n    labelX = [r.tolist() for i,r in df[labelcolumns].iterrows()] \n    return featureX,labelX\nfeatureX,labelX = splitRandomforestDataset(train_df)\nfeatureY,labelY = splitRandomforestDataset(valid_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators = 100, random_state = 31)\nrf.fit(featureX,labelX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = rf.predict(featureY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = metrics.accuracy_score(labelY, predictions)\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calcaulateMacroF1(allpred,allans,allpredacc,nclasses,rou=3):\n    recalls = [0 if allans[i] == 0 else 100*allpredacc[i]/allans[i] for  i in range(0,nclasses)]\n    precisions = [0 if allpred[i] == 0 else 100*allpredacc[i]/allpred[i] for  i in range(0,nclasses)]\n    avg_recalls = float(sum(recalls) / nclasses)\n    avg_precisions = float(sum(precisions) / nclasses)\n    beta=0.000001\n    macro_f1 =(2+beta)*(avg_recalls*avg_precisions)/((avg_recalls+avg_precisions)+beta)\n    macro_f1 = round(macro_f1,rou)\n    precisions = [round(p,rou) for p in precisions]\n    recalls = [round(r,rou) for r in recalls]\n    return macro_f1,recalls ,precisions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"totalacc=[0]*len(labelcolumns)\ntotalans=[0]*len(labelcolumns)\ntotalpred=[0]*len(labelcolumns)\nacc=0\nfor idx in range(len(predictions)):\n    allacc=True\n    pred = [int(p>0.5) for p in predictions[idx]]\n    if list(labelY[idx]) == list(pred):\n        acc+=1\n    for lidx in range(len(labelcolumns)):\n        if labelcolumns[lidx] in input_df.columns[-2:] and False:\n            totalans[lidx]+=not int(labelY[idx][lidx])\n            predvalue = pred[lidx]\n            totalpred[lidx]+= not predvalue\n            if labelY[idx][lidx] == predvalue:\n                totalacc[lidx]+= not predvalue\n        else:\n            totalans[lidx]+=int(labelY[idx][lidx])\n            predvalue = pred[lidx]\n            totalpred[lidx]+= predvalue\n            if labelY[idx][lidx] == predvalue:\n                totalacc[lidx]+= predvalue\nprint(acc/len(labelY))\nmacro_f1,recalls ,precisions = calcaulateMacroF1(totalpred,totalans,totalacc,len(labelcolumns))\nprint('f1-score: {} acc:{}'.format(\"%.3f\"%macro_f1,\"%.2f\"%(acc/len(labelY))))\nprint('\\nrecall: {} \\nprecis: {}'.format(recalls,precisions))\nprint(sum(precisions)/len(precisions),sum(recalls)/len(recalls))\nprint(metrics.accuracy_score(labelY, predictions))\nprint(metrics.precision_recall_fscore_support(labelY, predictions,average='micro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = read_csvfile(os.path.join(BASEPATH,\"test_data.csv\"))\ntest_df=test_df.drop(\"d.rainfall_detect\",axis=1)\nprint(featurecolumns)\ntest_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsubmit = read_csvfile(os.path.join(BASEPATH,\"submission.csv\"))\ntest_df[\"d.log_time\"] = [int(i.split(' ')[0].split('-')[1]+i.split(' ')[0].split('-')[2]+ i.split(' ')[1].split(':')[0]+ i.split(':')[1])/1e5  for i in test_df[\"d.log_time\"]]\nprint(test_df[\"d.log_time\"])\n\ntest_df = logData(test_df,\"d.wind_direction\")\nfor idx,columnsname in enumerate(columnsnames):\n    test_df = replacezerovalues(test_df,columnsname,False)\n    #test_df = logData(test_df,columnsname)\n\nnormalized_feature = dataNormalized(test_df,True)\n\ntest_df = normalized_feature\ndisplay(test_df.describe())\ndisplay(train_df[featurecolumns].describe())\nans = rf.predict(test_df[test_df.columns[1:]])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ans_df = pd.DataFrame(ans,columns=labelcolumns)\nans_df.to_csv(\"submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}