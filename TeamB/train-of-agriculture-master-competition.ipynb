{"cells":[{"metadata":{"_uuid":"4a3b595a-6d95-4298-a696-abc337cb7d84","_cell_guid":"f150530e-c30c-418c-af8e-8e5961e92555","trusted":true},"cell_type":"code","source":"import torch \nimport numpy as np\nimport sklearn\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\nfrom sklearn import  ensemble, preprocessing, metrics\nimport seaborn\nimport random\nimport pandas as pd\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch import nn\nimport os\nBASEPATH=\"../input/agriculture-master-competition\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CFG():\n    def __init__(self):\n        self.BATCHSIZE=2000\n        self.EPOCH=200\n        self.savescore=97\n        self.hiddenlayers=2\n        self.hiddennum=1000\n        self.DEVICE=torch.device('cuda')\ncfg=CFG()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_torch(seed=2021):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n#seed_torch()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf8eb911-8af7-4655-bc27-cdce181332cd","_cell_guid":"cc4f5734-9bb1-45c6-83b1-0d1badc0b5b4","trusted":true},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"_uuid":"4542f5bc-1d0f-4717-8ac5-b29e32655e1f","_cell_guid":"839f2726-9d82-49dc-8688-3f6c1de9a080","trusted":true},"cell_type":"code","source":"def read_csvfile(filepath):\n    df = pd.read_csv(filepath)\n    return df\ninput_df = read_csvfile(os.path.join(BASEPATH,\"train_data.csv\"))\nlabelcolumns = list(input_df.columns[20:])\nfeaturecolumns = list(input_df.columns[1:20])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pre-Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def removeOutlier(input_df):\n    input_df = input_df[input_df[\"d.wind_speed\"] != -9999]\n    input_df = input_df[input_df[\"d.photometric\"]<input_df[\"d.photometric\"].std()*3]\n    input_df = input_df[input_df[\"d.outside_photometric\"]<input_df[\"d.outside_photometric\"].std()*3]\n    input_df = input_df[input_df[\"d.radiometric\"]<input_df[\"d.radiometric\"].std()*3]\n    return input_df\ninput_df = removeOutlier(input_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def changeTimeFormat(input_df):\n    input_df[\"d.log_time\"] = [int(i.split(' ')[0].split('/')[1]+i.split(' ')[0].split('/')[2] + i.split(' ')[1].replace(':',''))/1e3 for i in input_df[\"d.log_time\"].tolist()]\n    print(input_df[\"d.log_time\"].iloc[0])\n    return input_df\ninput_df=changeTimeFormat(input_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def logData(df,columnsname):\n    df[columnsname]=df[columnsname].apply(lambda x: x if x!=0 else 000.1)\n    df[columnsname] = np.log(df[columnsname]).fillna(0)\n    return df\ninput_df = logData(input_df,\"d.wind_direction\")\ninput_df[featurecolumns].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def replacezerovalues(df,columnsname):\n    featureX = df[df[columnsname] != 0][featurecolumns].copy()\n    LabelX =featureX[columnsname].copy()\n    featureX = featureX.drop(columns=columnsname)\n    rf = RandomForestRegressor(n_estimators = 50, random_state = 2021)\n    rf.fit(featureX,LabelX)\n    \n    featureY = df[featurecolumns].copy()\n    featureY = featureY.drop(columns=columnsname)\n    newLabelY = rf.predict(featureY)\n    df[columnsname] = newLabelY\n    return df\n#columnsnames=[\"d.wind_speed\",\"d.radiometric\",\"d.outside_photometric\",\"d.photometric\"]\ncolumnsnames=[\"d.wind_speed\"]\nfor idx,columnsname in enumerate(columnsnames):\n    input_df = replacezerovalues(input_df,columnsname)\n#    input_df = logData(input_df,columnsname)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def showactuatorplot(df):\n    fig,ax =  plt.subplots(3,4,figsize=(17,10))\n    plotindex=0\n    for colname in labelcolumns:\n        x = list(set(df[colname]))\n        y=[]\n        sorted(x) \n        for i in x:\n            y.append(len(df[df[colname] == i]))\n        print(colname)\n        print(y[:10])\n        \n        ax[plotindex//4,plotindex%4].bar(x,y)\n        ax[plotindex//4,plotindex%4].set_title(colname)\n        plotindex+=1\n    fig.show()\n#showactuatorplot(input_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9e234ed4-adbf-46b5-990d-df32d3b4dc16","_cell_guid":"13bfbbfd-4689-424a-b47a-42f4298ec786","trusted":true},"cell_type":"code","source":"def dataNormalized(feature_df,zeromean=True):\n    if zeromean:\n        feature_df = (feature_df - feature_df.mean())/feature_df.std()\n    else:\n        feature_df=(feature_df-feature_df.min())/(feature_df.max()-feature_df.min())\n    feature_df[\"d.rainfall_detect\"]=0\n    return feature_df\nnormalized_feature = dataNormalized(input_df[featurecolumns],False)\ninput_df[featurecolumns] = normalized_feature","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b5e7858-b0d6-462b-a6c0-0acdbcba1cf7","_cell_guid":"e61e1674-e10b-4cbe-808f-f823fa2733fb","trusted":true},"cell_type":"code","source":"def balanceDataset(train_df,valid_df,minnum):\n    for lc in labelcolumns:\n        print(len(train_df[train_df[lc] == 0]),len(valid_df[valid_df[lc] == 0]),len(train_df[train_df[lc] == 1]),len(valid_df[valid_df[lc] == 1]))\n    print(\"===\")\n    for lc in labelcolumns:\n        l=0 if len(valid_df[valid_df[lc] == 1]) > len(valid_df[valid_df[lc] == 0]) else 1\n        trainn = len(train_df[train_df[lc] == l])\n        validn=len(valid_df[valid_df[lc] == l])\n        if validn+1 < minnum*(trainn+validn):\n            moven = (trainn+validn)*minnum-validn\n            move_rows = train_df[train_df[lc] == l].sample(frac=moven/trainn).copy()\n            valid_df=valid_df.append(move_rows)\n            train_df=train_df.drop(move_rows[\"index\"])\n\n            validnn=len(valid_df[valid_df[lc] == (not l)])\n            if validnn > len(move_rows):\n                move_rows = valid_df[valid_df[lc] == (not l)].sample(frac=len(move_rows)/validnn).copy()\n                train_df=train_df.append(move_rows)\n                valid_df=valid_df.drop(move_rows[\"index\"])\n    for lc in labelcolumns:\n        print(len(train_df[train_df[lc] == 0]),len(valid_df[valid_df[lc] == 0]),len(train_df[train_df[lc] == 1]),len(valid_df[valid_df[lc] == 1]))\n    return train_df,valid_df\n\n\ndef splitDataframe(df,train_sample):\n    shuffle_df = df.sample(frac=1,random_state=2021)\n    train_df,valid_df = np.split(shuffle_df,[int(train_sample*len(shuffle_df))])\n    #print(len(train_df),len(valid_df))\n    train_df,valid_df=balanceDataset(train_df,valid_df,0.2)\n    #print(len(train_df),len(valid_df))\n    return train_df,valid_df\n            \ntrain_df,valid_df=splitDataframe(input_df,0.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def trainDataframeBalance(df):\n    #showactuatorplot(df)\n    balancecolumns = labelcolumns[:6]\n    balance_df = pd.DataFrame(columns = df.columns)\n    for cn in balancecolumns:\n        balance_df=balance_df.append(df[df[cn] == 0].copy())\n        \n    balancecolumns = labelcolumns[-2:]\n    for cn in balancecolumns:\n        balance_df=balance_df.append(df[df[cn] == 1].copy())\n           \n    balancecolumns = labelcolumns[:6]\n    random.shuffle(balancecolumns)\n    for cn in balancecolumns:\n        tmp_zero=balance_df[balance_df[cn] == 0]\n        tmp_one=balance_df[balance_df[cn] == 1]\n        if 2*len(tmp_one)<len(tmp_zero):\n            balance_df=balance_df.append(df[df[cn] == 1].sample(frac=(len(tmp_zero)-len(tmp_one))/(len(tmp_zero)*2)))\n    #showactuatorplot(balance_df)\n    return balance_df\n#trainDataframeBalance(train_df)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getBalanceTrainingDataLoader(df):\n    balancetrain_df = trainDataframeBalance(df)\n    trainDataset=AgricultureDataset(df)\n    trainDataLoader = DataLoader(trainDataset,num_workers=5,shuffle=True,batch_size = cfg.BATCHSIZE)\n    return trainDataset,trainDataLoader\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a2a26b45-5efc-4228-a0c4-323b8cbd54de","_cell_guid":"c04b770e-cae6-4afd-9496-9a357e60320b","trusted":true},"cell_type":"code","source":"class AgricultureDataset(Dataset):\n    def __init__(self, df):\n        super().__init__()\n        self.dataframe = df\n        self.feature_df = df[featurecolumns]\n        self.label_df = df[labelcolumns]\n    \n    def __len__(self):\n        return self.dataframe.shape[0]\n    \n    def __getitem__(self, index: int):\n        \n        #self.feature_df = torch.from_numpy(self.feature_df)\n        return torch.FloatTensor(self.feature_df.iloc[index]),torch.FloatTensor(self.label_df.iloc[index])\ntrainDataset,trainDataLoader = getBalanceTrainingDataLoader(train_df)\nvalidDataset = AgricultureDataset(valid_df)\nvalidDataLoader = DataLoader(validDataset,num_workers=5,shuffle=False,batch_size = cfg.BATCHSIZE)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0179c7cc-f4b2-42d5-95fc-6496fc37b944","_cell_guid":"3d640448-bbaf-4dd4-b861-63151e2022b2","trusted":true},"cell_type":"code","source":"class swish(nn.Module):\n    def __init__(self):\n        super(swish, self).__init__()\n        self.sigmoid = nn.Sigmoid()\n    def forward(self, x):\n        x = x * self.sigmoid(x)\n        return x\n\nclass testModel(nn.Module):\n    def __init__(self,input_size,output_size,hiddenlayers,hiddennum):\n        super(testModel,self).__init__()\n        self.act = swish()\n        self.input_stem =  nn.Sequential(\n\n            nn.Linear(input_size,hiddennum),          \n            nn.BatchNorm1d(hiddennum),\n            self.act\n        )\n        hiddenlist =[]\n        for h in range(hiddenlayers):\n            hiddenlist.append(nn.Sequential(\n                nn.Linear(hiddennum,hiddennum),          \n                nn.BatchNorm1d(hiddennum),\n                nn.ReLU(inplace=True)\n            ))\n        self.hiddens = nn.Sequential(*hiddenlist)\n        self.output = nn.Sequential(\n            nn.Linear(hiddennum,output_size,bias=True), \n            nn.Sigmoid()\n        )\n    def forward(self,x):\n        x = self.input_stem(x)\n        x = self.hiddens(x)\n        return self.output(x)\nmodel = testModel(len(featurecolumns),len(labelcolumns),cfg.hiddenlayers,cfg.hiddennum).to(cfg.DEVICE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weight=torch.tensor([1,1,1,1,1,2,2,5,5,2,2]).to(cfg.DEVICE)\ncriterion = nn.BCELoss(weight=None, reduction='mean')#input:FloatTensor target:FloatTensor\n#criterion = nn.MSELoss(reduction='mean')\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=10, verbose=True, threshold=0.0001, cooldown=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calcaulateMacroF1(allpred,allans,allpredacc,nclasses,rou=3):\n    recalls = [0 if allans[i] == 0 else 100*allpredacc[i]/allans[i] for  i in range(0,nclasses)]\n    precisions = [0 if allpred[i] == 0 else 100*allpredacc[i]/allpred[i] for  i in range(0,nclasses)]\n    avg_recalls = float(sum(recalls) / nclasses)\n    avg_precisions = float(sum(precisions) / nclasses)\n    beta=0.000001\n    macro_f1 =(2+beta)*(avg_recalls*avg_precisions)/((avg_recalls+avg_precisions)+beta)\n    macro_f1 = round(macro_f1,rou)\n    precisions = [round(p,rou) for p in precisions]\n    recalls = [round(r,rou) for r in recalls]\n    return macro_f1,recalls ,precisions","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62def1b1-0698-4eef-8df9-b7747d248972","_cell_guid":"7b873436-f521-4ce8-8646-d4014e84947f","trusted":true},"cell_type":"code","source":"def evaluation(dataloader,model):\n    model.train()\n    totalloss=0\n    totalacc=[0]*len(labelcolumns)\n    totalans=[0]*len(labelcolumns)\n    totalpred=[0]*len(labelcolumns)\n    acc=0\n    totalscore=0\n    itter_count=0\n    for x,y in dataloader:\n        x = x.to(cfg.DEVICE)\n        y = y.to(cfg.DEVICE)\n        itter_count=1+itter_count\n        preds = model(x)\n        loss = criterion(preds,y)\n        totalloss+=loss.detach()\n        preds = preds.cpu().detach()\n        for idx in range(len(preds)):\n            allacc=True\n            pred = [int(p>0.5) for p in preds[idx]]\n            if list(y[idx]) == list(pred):\n                acc+=1\n            for lidx in range(len(labelcolumns)):\n                if labelcolumns[lidx] in input_df.columns[-2:]:\n                    totalans[lidx]+=not int(y[idx][lidx])\n                    predvalue = pred[lidx]\n                    totalpred[lidx]+= not predvalue\n                    if y[idx][lidx] == predvalue:\n                        totalacc[lidx]+= not predvalue\n                else:\n                    totalans[lidx]+=int(y[idx][lidx])\n                    predvalue = pred[lidx]\n                    totalpred[lidx]+= predvalue\n                    if y[idx][lidx] == predvalue:\n                        totalacc[lidx]+= predvalue\n        macro_f1,recalls ,precisions = calcaulateMacroF1(totalpred,totalans,totalacc,len(labelcolumns))\n        print('\\r{}/{} f1-score: {} acc:{} loss:{}'.format(\"%03d\"%itter_count,len(dataloader),\"%.3f\"%macro_f1,\"%.2f\"%(acc/((itter_count+1)*cfg.BATCHSIZE)),\"%.3f\"%round(float(totalloss/(itter_count+1)),3)),end='',flush=True)\n    if cfg.savescore<macro_f1:\n        torch.save(model.state_dict(), f\"{macro_f1}.pkl\")\n        cfg.savescore = macro_f1\n    scheduler.step(macro_f1)\n    print('\\r{}/{} f1-score: {} acc:{} loss:{}'.format(\"%03d\"%itter_count,len(dataloader),\"%.3f\"%macro_f1,\"%.2f\"%(acc/len(validDataset)),\"%.3f\"%round(float(totalloss/(itter_count)),3)),end='',flush=True)\n    print('\\nrecall: {} \\nprecis: {}'.format(recalls,precisions))\n\ndef train_one_eopch(dataloader,model,criterion,optimizer):\n    model.train()\n    totalloss=0\n    totalacc=[0]*len(labelcolumns)\n    totalans=[0]*len(labelcolumns)\n    totalpred=[0]*len(labelcolumns)\n    acc=0\n    totalscore=0\n    itter_count=0\n    for x,y in dataloader:\n        itter_count+=1\n        x = x.to(cfg.DEVICE)\n        y = y.to(cfg.DEVICE)\n        preds = model(x)\n        optimizer.zero_grad()\n        loss = criterion(preds,y)\n        loss.backward()\n        optimizer.step()\n        totalloss+=loss.detach()\n        preds = preds.cpu().detach()\n        \n        for idx in range(len(preds)):\n            allacc=True\n            pred = [int(p>0.5) for p in preds[idx]]\n            if list(y[idx]) == list(pred):\n                acc+=1\n            for lidx in range(len(labelcolumns)):\n                if labelcolumns[lidx] in input_df.columns[-2:]:\n                    totalans[lidx]+=not int(y[idx][lidx])\n                    predvalue = pred[lidx]\n                    totalpred[lidx]+= not predvalue\n                    if y[idx][lidx] == predvalue:\n                        totalacc[lidx]+= not predvalue\n                else:\n                    totalans[lidx]+=int(y[idx][lidx])\n                    predvalue = pred[lidx]\n                    totalpred[lidx]+= predvalue\n                    if y[idx][lidx] == predvalue:\n                        totalacc[lidx]+= predvalue\n        macro_f1,recalls ,precisions = calcaulateMacroF1(totalpred,totalans,totalacc,len(labelcolumns))\n        print('\\r{}/{} f1-score: {} acc:{} loss:{}'.format(\"%03d\"%itter_count,len(dataloader),\"%.3f\"%macro_f1,\"%.2f\"%(acc/((itter_count)*cfg.BATCHSIZE)),\"%.3f\"%round(float(totalloss/(itter_count)),3)),end='',flush=True)\n    print('\\r{}/{} f1-score: {} acc:{} loss:{}'.format(\"%03d\"%itter_count,len(dataloader),\"%.3f\"%macro_f1,\"%.2f\"%(acc/len(trainDataset)),\"%.3f\"%round(float(totalloss/(itter_count)),3)),end='',flush=True)\n    print('\\nrecall: {} \\nprecis: {}'.format(recalls,precisions))\n        \nfor e in range(cfg.EPOCH):\n    print(f\"\\nEPOCH:{e+1}\")\n    trainDataset,trainDataLoader = getBalanceTrainingDataLoader(train_df)\n    train_one_eopch(trainDataLoader,model,criterion,optimizer)\n    print('')\n    evaluation(validDataLoader,model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}